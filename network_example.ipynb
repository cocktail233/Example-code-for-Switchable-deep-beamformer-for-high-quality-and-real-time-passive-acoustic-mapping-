{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.io as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block with instance normalization.\"\"\"\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)\n",
    "\n",
    "class LocalAwareAttention(nn.Module):\n",
    "    def __init__(self, channels, beta=0.5):\n",
    "        super(LocalAwareAttention, self).__init__()\n",
    "\n",
    "        self.beta = beta\n",
    "\n",
    "        self.avg = nn.AvgPool2d(kernel_size=4,stride=2,padding=1)\n",
    "        self.up = nn.ConvTranspose2d(channels, channels, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.avg(x)\n",
    "        x1 = self.up(x1)\n",
    "        x1 = x1 * self.relu(x1 - x) * self.beta\n",
    "        x1 = x + x1\n",
    "        return x1\n",
    "\n",
    "class PA(nn.Module):\n",
    "    '''PA is pixel attention'''\n",
    "    def __init__(self, nf):\n",
    "\n",
    "        super(PA, self).__init__()\n",
    "        self.conv = nn.Conv2d(nf, nf, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = self.conv(x)\n",
    "        y = self.sigmoid(y)\n",
    "        out = torch.mul(x, y)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarGanGenerator(nn.Module):\n",
    "    \"\"\"Generator network.\"\"\"\n",
    "    def __init__(self, input_nc=1, output_nc=1, conv_dim=64, c_dim=5, repeat_num=6, masked=True):\n",
    "        super(StarGanGenerator, self).__init__()\n",
    "\n",
    "        self.masked = masked\n",
    "        if self.masked == False:\n",
    "            c_dim = 0\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(input_nc+c_dim, conv_dim, kernel_size=7, stride=1, padding=3, bias=False))\n",
    "        layers.append(nn.InstanceNorm2d(conv_dim, affine=True, track_running_stats=True))\n",
    "        layers.append(nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        # Down-sampling layers.\n",
    "        curr_dim = conv_dim\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "            layers.append(nn.InstanceNorm2d(curr_dim*2, affine=True, track_running_stats=True))\n",
    "            layers.append(nn.LeakyReLU(inplace=True))\n",
    "            curr_dim = curr_dim * 2\n",
    "\n",
    "        # Bottleneck layers.\n",
    "        for i in range(repeat_num):\n",
    "            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n",
    "            layers.append(LocalAwareAttention(channels=curr_dim))\n",
    "\n",
    "        # Up-sampling layers.\n",
    "        for i in range(3):\n",
    "            layers.append(PA(curr_dim))\n",
    "            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "            layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True, track_running_stats=True))\n",
    "            layers.append(nn.LeakyReLU(inplace=True))\n",
    "            curr_dim = curr_dim // 2\n",
    "\n",
    "        layers.append(PA(curr_dim))\n",
    "        layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=(1,4), stride=(1,2), padding=(0,1), bias=False))\n",
    "        layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True, track_running_stats=True))\n",
    "        layers.append(nn.LeakyReLU(inplace=True))\n",
    "        curr_dim = curr_dim // 2\n",
    "\n",
    "        layers.append(nn.Conv2d(curr_dim, output_nc, kernel_size=7, stride=1, padding=3, bias=False))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, c=None):\n",
    "        if self.masked == True:\n",
    "            c = c.view(c.size(0), c.size(1), 1, 1)\n",
    "            c = c.repeat(1, 1, x.size(2), x.size(3))\n",
    "            x = torch.cat([x, c], dim=1)\n",
    "            y = self.main(x)\n",
    "        else:\n",
    "            y = self.main(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.ids = [splitext(file)[0] for file in listdir(data_dir) if not file.startswith('.')]\n",
    "        self.type = []\n",
    "        if not self.ids:\n",
    "            raise RuntimeError(f'No input file found in {data_dir}, make sure you put your images there')\n",
    "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess(cls, pil_img, is_mask):\n",
    "        img_ndarray = np.asarray(pil_img)\n",
    "        if not is_mask:\n",
    "            img_ndarray = img_ndarray.astype(np.float32)\n",
    "            img_ndarray = img_ndarray[np.newaxis, ...]\n",
    "            img_ndarray = img_ndarray / np.max(np.abs(img_ndarray))\n",
    "\n",
    "            return img_ndarray\n",
    "\n",
    "        if is_mask:\n",
    "            img_ndarray = img_ndarray.astype(np.float32)\n",
    "            img_ndarray = (img_ndarray - np.min(img_ndarray)) / (np.max(img_ndarray)-np.min(img_ndarray))\n",
    "            img_ndarray = img_ndarray * 2.0 - 1.0\n",
    "            img_ndarray = img_ndarray[np.newaxis, :, 0:512]\n",
    "            return img_ndarray\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        dic = h5py.File(filename)\n",
    "\n",
    "        rf = np.transpose(dic['RF'],[1,0])\n",
    "        img = np.transpose(dic['Img'], [1, 0])\n",
    "\n",
    "        return rf, img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.ids[idx]\n",
    "        file = list(self.data_dir.glob(name + '.*'))\n",
    "\n",
    "        rf, img = self.load(file[0])\n",
    "\n",
    "        ## crop RF\n",
    "        Nt,Nc = rf.shape\n",
    "\n",
    "        rf_tmp1 = np.copy(rf)\n",
    "        rf_tmp2 = np.copy(rf)\n",
    "        threshold1 = 0.3\n",
    "        threshold2 = 0.01\n",
    "\n",
    "        rf_tmp1[np.abs(rf_tmp1) < threshold1] = 0\n",
    "        rf_tmp2[np.abs(rf_tmp2) < threshold2] = 0\n",
    "        non_zero_indices = np.nonzero(rf_tmp1)\n",
    "\n",
    "        t_min = np.min(non_zero_indices[0])\n",
    "        t_max = np.max(non_zero_indices[0])\n",
    "\n",
    "        ## The sliding window is fixed to select a stable middle segment of the signal.\n",
    "        upper = int((t_min + t_max) / 2) - 128\n",
    "        lower = int((t_min + t_max) / 2) + 128\n",
    "\n",
    "        ## The sliding window is randomly shifted, which may result in selecting poor-quality signals, but this is necessary during training.\n",
    "        # if t_max - 256 <= t_min:\n",
    "        #     offset = random.randint(-64, 64)\n",
    "        #     upper = int((t_min + t_max) / 2) - 128 + offset\n",
    "        #     lower = int((t_min + t_max) / 2) + 128 + offset\n",
    "        # else:\n",
    "        #     upper = random.randint(t_min, t_max - 256)\n",
    "        #     lower = upper + 256\n",
    "        # if upper < 0:\n",
    "        #     upper = 0\n",
    "        #     lower = 256\n",
    "        # if lower >= Nt:\n",
    "        #     upper = Nt-256\n",
    "        #     lower = Nt       \n",
    "\n",
    "        ## Crop the data\n",
    "        rf_crop = rf_tmp2[upper:lower, :]\n",
    "\n",
    "        ## Global normalization\n",
    "        rf_norm = rf_crop / np.max(np.abs(rf_crop))\n",
    "\n",
    "        ##\n",
    "        rf = self.preprocess(rf_norm, is_mask=False)\n",
    "\n",
    "        img = self.preprocess(img, is_mask=True)\n",
    "\n",
    "        return {\n",
    "            'A': torch.as_tensor(rf.copy()).float().contiguous(),\n",
    "            'B': torch.as_tensor(img.copy()).float().contiguous(),\n",
    "            'name': name,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_instance_norm_running_stats(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.InstanceNorm2d):\n",
    "            m.track_running_stats = False\n",
    "            m.running_mean = None\n",
    "            m.running_var = None\n",
    "\n",
    "net = StarGanGenerator(input_nc=1, output_nc=1, c_dim=3, masked=True)\n",
    "net.load_state_dict(torch.load(\"model\\\\latest_net_G.pth\"))\n",
    "net.to(0)\n",
    "net.eval()\n",
    "disable_instance_norm_running_stats(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def get_label(trans_type):\n",
    "    # get mask vector\n",
    "    # P4-1: trans_type=1\n",
    "    # L7-4: trans_type=2\n",
    "    # CL15-7: trans_type=3\n",
    "\n",
    "    clc = [1, 2, 3]\n",
    "    label = np.zeros((1,len(clc)),dtype=np.float32)\n",
    "    for i in range(3):\n",
    "        if trans_type == clc[i]:\n",
    "            label[0,i] = 1\n",
    "    return label\n",
    "\n",
    "## Example for P4-1\n",
    "dir_data = Path('.\\\\data\\\\P4-1\\\\')\n",
    "trans_type = 1\n",
    "\n",
    "## Example for L7-4\n",
    "# dir_data = Path('.\\\\data\\\\L7-4\\\\')\n",
    "# trans_type = 2\n",
    "\n",
    "## Example for CL15-7\n",
    "# dir_data = Path('.\\\\data\\\\CL15-7\\\\')\n",
    "# trans_type = 3\n",
    "\n",
    "img_path1 = 'imgs/DNN/'\n",
    "img_path2 = 'imgs/EISRCB/'\n",
    "\n",
    "dataset = BasicDataset(dir_data)\n",
    "loader_args = dict(batch_size=1, num_workers=0, pin_memory=False)\n",
    "train_loader = DataLoader(dataset, shuffle=False, **loader_args)\n",
    "\n",
    "i=0\n",
    "for data in train_loader:\n",
    "\n",
    "    input_data = data['A'].to(0)\n",
    "    if trans_type == 1:\n",
    "        input_data = F.pad(input_data, pad=(16, 16), mode='constant', value=0)\n",
    "\n",
    "    label = torch.as_tensor(get_label(trans_type)).to(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net.forward(input_data,label)\n",
    "\n",
    "    output = output.cpu().detach().numpy()\n",
    "    output = np.squeeze(output)\n",
    "\n",
    "    io.savemat(img_path1 + 'DNN_Img_' + data['name'][0] + '.mat',{'DNN_Img':output})\n",
    "    io.savemat(img_path2 + 'EISRCB_Img_' + data['name'][0] + '.mat', {'EISRCB_Img': np.squeeze(data['B'].cpu().detach().numpy()),\n",
    "                                                                'label': np.squeeze(label.cpu().detach().numpy())})\n",
    "\n",
    "    i = i+1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
